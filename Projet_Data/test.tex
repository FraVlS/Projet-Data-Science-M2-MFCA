% ==========================================================
%  COMPTE RENDU DE PROJET - DATA SCIENCE (FORMAT SPÉCIFIÉ)
% ==========================================================
\documentclass[12pt,a4paper]{report}

% ========== PACKAGES ==========
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{lmodern}
\usepackage{csquotes}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{pdfpages}
\usepackage{appendix}
\usepackage{siunitx}
\sisetup{detect-weight=true, detect-inline-weight=math}
\usepackage{titlesec}

% ========== PAGE SETTINGS ==========
\geometry{left=2.5cm, right=2.5cm, top=0.5cm, bottom=2.5cm}
\linespread{1.15} % interligne réduit
\setlength{\parskip}{0.5em} % espace paragraphe réduit
% Réduire les espaces autour des figures
\setlength{\floatsep}{0.5em}
\setlength{\textfloatsep}{0.5em}
\setlength{\intextsep}{0.5em}
\setlength{\abovecaptionskip}{0.3em}
\setlength{\belowcaptionskip}{0.2em}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=teal,
    citecolor=purple
}

% ========== HEADER / FOOTER ==========
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Compte rendu de projet Data Science}
\fancyhead[R]{\small\thepage}
\renewcommand{\headrulewidth}{0.4pt}
% Supprimer les numéros de chapitre dans les en-têtes
\renewcommand{\chaptermark}[1]{\markboth{}{}}
\renewcommand{\sectionmark}[1]{\markright{}}

% ========== REMOVE "CHAPTER" WORD AND NUMBER ==========
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}{}{0pt}{\Huge}
\titlespacing*{\chapter}{0pt}{-40pt}{0pt}  % Réduire l'espace avant le chapitre (left, top, bottom)

% ========== SOMMAIRE COMPACT ==========
\usepackage{tocloft}
\renewcommand{\cftbeforechapskip}{0.5em} % espace avant chapitres réduit
\renewcommand{\cftbeforesecskip}{0.2em}  % espace avant sections réduit
\renewcommand{\cftchapfont}{\small}      % police plus petite
\renewcommand{\cftsecfont}{\small}
\renewcommand{\cftchappagefont}{\small}
\renewcommand{\cftsecpagefont}{\small}

% ========== REDUCE SPACE BEFORE TOC ==========
\setlength{\cftbeforetoctitleskip}{0.3cm}

% ==========================================================
%  TITRE
% ==========================================================
\begin{document}

\begin{titlepage}
\newgeometry{top=4cm,left=2.5cm,right=2.5cm,bottom=2.5cm}
    \centering
    {\Large \textbf{Université de Lille}}\\[0.5cm]
    {\large Master 2 Mathématiques, Finance et Actuariat}\\[1.5cm]

    {\huge \bfseries Compte rendu du projet de \\[0.2cm]
    Data Science}\\[1.5cm]

    \vspace{1cm}
    \textbf{Auteurs :} Timothé Kuntzsmann \& Valentin Martiaux\\[0.2cm]
    \textbf{Professeur :} Olivier Bouaziz\\[1cm]

    \vfill
    \textbf{Date :} \today\\[2cm]
    \includegraphics[width=0.25\textwidth]{logo-univ-lille.png}
\end{titlepage}
\restoregeometry

% ==========================================================
%  SOMMAIRE
% ==========================================================

{\small % rend tout le sommaire plus petit
\tableofcontents
}
\pagenumbering{arabic}

% ==========================================================
\chapter{Statistiques Descriptives sur la Base de données}

\section{Description et présentation des données}
La base de données a pour thématique le cancer du sein et contient au total 569 observations de cellules. Chaque observation est caractérisée par 30 variables numériques représenant différentes caractéristiques des cellules (rayon, périmètre, aire, texture, etc...), calculées en moyenne (\_mean), en écart-type (\_se) et en valeur maximale (\_worst).

Les principales variables du dataset sont les suivantes (selon le fichier wdbc.names): 
\begin{itemize}
    \item[a)] \textbf{radius} : moyenne des distances entre le centre et les points du périmètre
    \item[b)] \textbf{texture} : écart-type des valeurs en niveaux de gris
    \item[c)] \textbf{perimeter} : périmètre
    \item[d)] \textbf{area} : aire
    \item[e)] \textbf{smoothness} : variation locale des longueurs de rayon
    \item[f)] \textbf{compactness} : $\dfrac{perimeter^2}{area} - 1.0$
    \item[g)] \textbf{concavity} : sévérité des portions concaves du contour
    \item[h)] \textbf{concave points} : nombre de portions concaves du contour
    \item[i)] \textbf{symmetry} : symétrie
    \item[j)] \textbf{fractal dimension} : « approximation de la côte » $-\,1$
\end{itemize}


La variable cible est le diagnostique (de nom Diagnostic dans le dataset), une variable à valeurs dans {B,M} que l'on recode de manière binaire afin de mieux l'étudier, avec la transformation suivante:
\begin{itemize}
    \item 0 : Benign (Bénin)
    \item 1 : Malignant (Malin)
\end{itemize}

\section{Matrice de Corrélation}
La matrice de corrélation permet d'observer les relations entre les variables. Les variables fortement corrélées peuvent être redondantes et  prises en compte lors de la réduction de dimension. Comme le montre l'image ~\ref{fig:correlation_matrix}, certaines variables sont fortement corrélées entre elles, ce qui peut justifier l'utilisation de techniques de réduction de dimensionnalité comme l'ACP par la suite.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{code_PCA_LDA_correlation_matrix.png}
\caption{Matrice de corrélation entre les variables du dataset}
\label{fig:correlation_matrix}
\end{figure}

Les variables présentant une forte corrélation sont les variables qui concernent les rayons et la concavité, ainsi que le périmètre et la dimension fractale notamment. On retrouve également assez souvent des corrélations entre les même variables dans leurs catégories se et worst. Les variable d'aire moyenne et concavité moyenne sont peu corrélées avec les autres variables . 

\section{Analyse de l'équilibre des classes}
Le dataset présente le déséquilibre suivant entre les classes B et M:

\begin{itemize}
    \item \textbf{Benign (Bénin)} : 357 observations (environ 63\%)
    \item \textbf{Malignant (Malin)} : 212 observations (environ 37\%)
    \item \textbf{Ratio} : 1.684 (Benign/Malignant)
\end{itemize}

Ce déséquilibre, bien que modéré, nécessite une attention particulière lors de l'entraînement des modèles. Un split stratifié a été utilisé pour maintenir la distribution des classes dans les ensembles d'entraînement et de test. Certains modèles ont également utilisé des techniques d'équilibrage comme \texttt{class\_weight='balanced'} ou des méthodes d'oversampling comme SMOTE ou NearMiss.

% ==========================================================
\chapter{Méthode d'Évaluation des Erreurs des Modèles}

\section{Métriques utilisées}
Plusieurs métriques ont été utilisées pour évaluer les performances des modèles :

\begin{itemize}
    \item \textbf{Accuracy (Précision globale)} : proportion d'observations correctement classées
    \item \textbf{Precision} : proportion de prédictions positives qui sont réellement positives $TP / (TP + FP)$
    \item \textbf{Recall (Sensibilité)} : proportion de cas positifs réellement détectés $TP / (TP + FN)$
    \item \textbf{Specificity} : proportion de cas négatifs réellement détectés $TN / (TN + FP)$
    \item \textbf{F1-score} : moyenne de la précision et du rappel $2 \times (Precision \times Recall) / (Precision + Recall)$
    \item \textbf{AUC} : aire sous la courbe ROC, mesure la capacité du modèle à distinguer les classes
\end{itemize}

Ces métriques permettent d'évaluer les modèles sous différents angles, ce qui est particulièrement important dans un contexte médical où les faux négatifs (manquer un cancer présent) sont à éviter.

\section{Validation croisée}
Une validation croisée avec 5 folds (5-fold cross-validation) a été utilisée pour l'optimisation des hyperparamètres et la sélection des modèles. Cette méthode divise le dataset en 5 sous-ensembles, entraîne le modèle sur 4 folds et évalue sur le fold restant, en répétant le processus 5 fois. Cela permet d'obtenir une meilleure estimation des performances en donnant à chaque donnée l'occasion d'être une donnée d'entraînement et de test.

Pour certains modèles (KNN, Random Forest), une recherche grid search a été utilisée pour trouver les meilleurs hyperparamètres.

% ==========================================================
\chapter{LDA}

\section{Description du modèle}
L'Analyse Discriminante Linéaire (LDA) suppose que les données suivent une distribution gaussienne multivariée avec une matrice de covariance commune $\boldsymbol{\Sigma}$. Cette méthode est adaptée à notre problème car les caractéristiques biologiques suivent généralement des distributions approximativement normales et l'hypothèse de covariance commune simplifie l'estimation avec 30 variables corrélées.

La fonction de décision pour une classe $k$ est :

\begin{equation}
\delta_k(\mathbf{x}) = \mathbf{x}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_k - \frac{1}{2} \boldsymbol{\mu}_k^T \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_k + \log(\pi_k)
\end{equation}

où $\boldsymbol{\mu}_k$ est le vecteur moyen de la classe $k$ et $\pi_k$ la probabilité a priori. La classification attribue l'observation à la classe qui maximise $\delta_k(\mathbf{x})$.

% Décision binaire (0/1) sous forme linéaire
\[
\,f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + w_0,\quad \mathbf{w} = \boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0),\quad
w_0 = -\tfrac{1}{2}(\boldsymbol{\mu}_1 + \boldsymbol{\mu}_0)^T \boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) + \log\frac{\pi_1}{\pi_0}
\]
Décision: classe 1 si $f(\mathbf{x})>0$.

\section{Résultats}

\begin{table}[H]
\centering
\caption{Matrice de confusion - LDA}
\label{tab:confusion_lda}
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Prédit B} & \textbf{Prédit M} \\
\hline
\textbf{Vrai Bénin} & 72 & 0 \\
\hline
\textbf{Vrai Malignant} & 2 & 40 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métriques de performance - LDA}
\label{tab:metrics_lda}
\begin{tabular}{lcc}
\toprule
\textbf{Métrique} & \textbf{B} & \textbf{M} \\
\midrule
Precision & 0.97 & 1.00 \\
Recall & 1.00 & 0.95 \\
F1-score & 0.99 & 0.98 \\
\midrule
Accuracy & \multicolumn{2}{c}{0.98} \\
Macro avg & \multicolumn{2}{c}{0.98} \\
Weighted avg & \multicolumn{2}{c}{0.98} \\
\bottomrule
\end{tabular}
\end{table}

Le modèle LDA obtient une excellente performance avec une précision de 98\%. Il prédit parfaitement les cas bénins (72 sur 72), mais commet 2 faux négatifs sur les cas malins (2 sur 42). L'AUC est de 0.997, ce qui indique une excellente capacité de discrimination.

% ==========================================================
\chapter{QDA}

\section{Description du modèle}
L'Analyse Discriminante Quadratique (QDA) étend le LDA en permettant à chaque classe d'avoir sa propre matrice de covariance $\boldsymbol{\Sigma}_k$. Cette flexibilité est utile car les cellules bénignes et malignes peuvent avoir des dispersions différentes dans l'espace des caractéristiques biologiques.

La fonction de décision quadratique est :

\begin{equation}
\delta_k(\mathbf{x}) = -\frac{1}{2} \log|\boldsymbol{\Sigma}_k| - \frac{1}{2} (\mathbf{x} - \boldsymbol{\mu}_k)^T \boldsymbol{\Sigma}_k^{-1} (\mathbf{x} - \boldsymbol{\mu}_k) + \log(\pi_k)
\end{equation}

Le terme quadratique représente la distance de Mahalanobis, qui prend en compte la forme et l'orientation de chaque distribution. La frontière de décision devient ainsi quadratique au lieu de linéaire.

% Frontière quadratique binaire (entre classes i et j)
\[
\mathbf{x}^T(\boldsymbol{\Sigma}_i^{-1} - \boldsymbol{\Sigma}_j^{-1})\mathbf{x}
+ 2(\boldsymbol{\mu}_j^T \boldsymbol{\Sigma}_j^{-1} - \boldsymbol{\mu}_i^T \boldsymbol{\Sigma}_i^{-1})\mathbf{x} + c = 0,
\]
où $c$ regroupe les constantes (termes quadratiques en $\boldsymbol{\mu}_k$, déterminants et priors).

\section{Résultats}

\begin{table}[H]
\centering
\caption{Matrice de confusion - QDA}
\label{tab:confusion_qda}
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Prédit B} & \textbf{Prédit M} \\
\hline
\textbf{Vrai Bénin} & 66 & 6 \\
\hline
\textbf{Vrai Malignant} & 1 & 41 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métriques de performance - QDA}
\label{tab:metrics_qda}
\begin{tabular}{lcc}
\toprule
\textbf{Métrique} & \textbf{B} & \textbf{M} \\
\midrule
Precision & 0.99 & 0.87 \\
Recall & 0.92 & 0.98 \\
F1-score & 0.95 & 0.92 \\
\midrule
Accuracy & \multicolumn{2}{c}{0.94} \\
Macro avg & \multicolumn{2}{c}{0.94} \\
Weighted avg & \multicolumn{2}{c}{0.94} \\
\bottomrule
\end{tabular}
\end{table}

Le modèle QDA présente une performance légèrement inférieure au LDA avec une précision de 94\%. Il commet 6 faux positifs et 1 faux négatif. L'AUC est de 0.989, restant très élevée. La flexibilité supplémentaire du QDA ne semble pas améliorer les performances dans ce cas, probablement en raison d'un nombre limité d'observations.

% ==========================================================
\chapter{Régression Logistique}

\section{Description du modèle}
La régression logistique modélise la probabilité d'appartenance à une classe via la fonction sigmoïde.
\[
X = 
\begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1m} \\
x_{21} & x_{22} & \cdots & x_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{nm}
\end{bmatrix}
\]
Et la variable dépendante  ayant seulement des valeurs binaires
\[
Y = 
\begin{cases} 
0 & \text{si Classe 1} \\
1 & \text{si Classe 2}
\end{cases}
\]
Ensuite on applique la fonction multi-linéaire aux variables d’entrée 
\[
z = \left( \sum_{i=1}^{n} w_i x_i \right) + b
\]
Ici $x_i$ est la $i_{\text{ème}}$ observation de $X$, $w_i = [w_1, w_2, w_3, \cdots, w_m]$ sont les poids ou coefficients et $b$ est le terme de biais. Finalement on peut représenter l’expression comme le produit scalaire des poids et du biais. Finalement on peut représenter l’expression comme le produit scalaire des poids et du biais :\[
z = {W}{X} + b
\]
La régression logistique applique ensuite la fonction sigmoïde à  pour la convertir en probabilité :\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]
Ce modèle est adapté à notre problème car il fournit des probabilités interprétables cliniquement, les coefficients reflètent l'impact de chaque caractéristique sur le risque de cancer, et il fonctionne bien avec des variables corrélées. 

On construit 3 modèles variants de la régression logistique, dont les paramètres sont optimisés par la fonction GridsearchCV, qui subdivise le set d’entraînement en entraînement et en validation pour la recherche de paramètres optimaux en validation croisée.
Le premier modèle constitue un modèle simple, sans algorithme de sampling.
Le second emploie une fonction de sous-échantillonnage visant à réduire la classe majoritaire pour équilibrer la proportion de classes.
Le troisième repose sur la technique inverse, c’est-à-dire synthétiser de nouvelles données pour la classe minoritaire via k-plus proches voisins.
\includepdf\includepdf[
  pages=1,
  scale=110, % Réduit à 80% de la taille originale
  offset=0mm -10mm{schema_comparaison_modeles_v2.pdf}

\section{Résultats}

\begin{table}[H]
\centering
\caption{Matrice de confusion - Régression Logistique}
\label{tab:confusion_lr}
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Prédit B} & \textbf{Prédit M} \\
\hline
\textbf{Vrai Bénin} & 72 & 0 \\
\hline
\textbf{Vrai Malignant} & 2 & 40 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métriques de performance - Régression Logistique}
\label{tab:metrics_lr}
\begin{tabular}{lcc}
\toprule
\textbf{Métrique} & \textbf{B} & \textbf{M} \\
\midrule
Precision & 0.97 & 1.00 \\
Recall & 1.00 & 0.95 \\
F1-score & 0.99 & 0.98 \\
\midrule
Accuracy & \multicolumn{2}{c}{0.98} \\
Macro avg & \multicolumn{2}{c}{0.98} \\
Weighted avg & \multicolumn{2}{c}{0.98} \\
\bottomrule
\end{tabular}
\end{table}

La régression logistique obtient d'excellentes performances avec une précision de 98\%. Elle prédit parfaitement les cas bénins (72 sur 72, 0 faux positif) et commet seulement 2 faux négatifs. L'AUC de 0.995 est très élevée, confirmant la qualité du modèle. L'utilisation de \texttt{class\_weight='balanced'} a permis d'obtenir un bon équilibre entre les deux classes.

% ==========================================================
\chapter{Régression Logistique + PCA}

\section{Application de la PCA}
L'Analyse en Composantes Principales (PCA) transforme les variables corrélées en composantes principales non corrélées, ordonnées par variance expliquée. Cette technique est utile pour notre problème car elle réduit la redondance parmi les 30 variables corrélées, permet de visualiser la séparation des classes dans un espace de dimension réduite, et peut améliorer les performances en réduisant le bruit.

Les figures~\ref{fig:pca_variance_per_axis} et~\ref{fig:pca_cumulative_variance} montrent respectivement la variance expliquée par chaque axe et la variance cumulée. Les figures~\ref{fig:pca_auc_axes} et~\ref{fig:pca_aic_bic} permettent de sélectionner le nombre optimal d'axes, fixé à 5 dans ce projet.

\begin{figure}[H]
\centering
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Part de n axe à l explication de la variance.png}
\caption{Variance par axe}
\label{fig:pca_variance_per_axis}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Part de variance expliquée par n axes.png}
\caption{Variance cumulée}
\label{fig:pca_cumulative_variance}
\end{subfigure}
\caption{Analyse de la variance expliquée par la PCA}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{AUC en fonction du nombre d'axes PCA.png}
\caption{AUC vs nombre d'axes}
\label{fig:pca_auc_axes}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{AIC et BIC selon le nombre d'axes PCA.png}
\caption{Critères AIC et BIC}
\label{fig:pca_aic_bic}
\end{subfigure}
\caption{Sélection du nombre optimal d'axes PCA}
\end{figure}

\section{Résultats}
La régression logistique appliquée aux données transformées par PCA (5 axes) obtient une AUC de 0.996, proche de celle sans PCA (0.995). La projection sur les deux premiers axes (figure~\ref{fig:pca_projection_2d}) montre une bonne séparation visuelle entre les classes. Les cercles des corrélations (figures~\ref{fig:pca_circle_12} et~\ref{fig:pca_circle_23}) et les contributions des variables (figures~\ref{fig:pca_contrib_axis1},~\ref{fig:pca_contrib_axis2} et~\ref{fig:pca_wordcloud_pc1}) identifient les caractéristiques les plus importantes.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Projection des patients sur le plan des deux premiers axes PCA.png}
\caption{Projection des patients sur le plan formé par les deux premiers axes PCA, colorée selon le diagnostic. On observe une bonne séparation entre les classes.}
\label{fig:pca_projection_2d}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Courbe ROC de la Régression Logistique sur 5 axes de la PCA.png}
\caption{Courbe ROC de la régression logistique appliquée aux données transformées par PCA (5 axes)}
\label{fig:pca_roc_lr}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Correlation Circle Plot axe 1&2.png}
\caption{Axes 1 et 2}
\label{fig:pca_circle_12}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Correlation Circle Plot axe 2&3.png}
\caption{Axes 2 et 3}
\label{fig:pca_circle_23}
\end{subfigure}
\caption{Cercles des corrélations montrant les contributions des variables aux différents axes}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Contributions des variables à l'axe 1.png}
\caption{Contributions axe 1}
\label{fig:pca_contrib_axis1}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Contributions des variables à l'axe 2.png}
\caption{Contributions axe 2}
\label{fig:pca_contrib_axis2}
\end{subfigure}
\caption{Contributions des variables aux deux premières composantes principales}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{Nuage de mots PC1.png}
\caption{Nuage de mots représentant les contributions des variables à la première composante principale (PC1)}
\label{fig:pca_wordcloud_pc1}
\end{figure}

La comparaison montre que la PCA n'apporte pas d'amélioration significative dans ce cas, probablement parce que toutes les caractéristiques originales sont déjà pertinentes pour la classification. Cependant, l'utilisation de seulement 5 composantes au lieu de 30 variables réduit le risque de sur-apprentissage et simplifie l'interprétation du modèle.

% ==========================================================
\chapter{Régression Logistique + NearMiss}

\section{Principe de NearMiss}
NearMiss est une technique d'undersampling qui réduit le nombre d'observations de la classe majoritaire en sélectionnant les exemples les plus proches de la classe minoritaire. Cette approche permet de créer un dataset équilibré tout en conservant les informations les plus pertinentes pour la classification.

Il existe plusieurs variantes de NearMiss :
\begin{itemize}
    \item NearMiss-1 : sélectionne les exemples de la classe majoritaire dont la distance moyenne aux $k$ plus proches voisins de la classe minoritaire est la plus petite
    \item NearMiss-2 : sélectionne les exemples dont la distance moyenne aux $k$ plus lointains voisins de la classe minoritaire est la plus petite
    \item NearMiss-3 : sélectionne un nombre fixe d'exemples de la classe majoritaire pour chaque exemple de la classe minoritaire
\end{itemize}

Dans ce projet, NearMiss a été utilisé en combinaison avec la régression logistique pour équilibrer les classes avant l'entraînement du modèle.

\section{Résultats}


% ==========================================================
\chapter{KNN}

\section{Description du modèle}
Le K-Nearest Neighbors (KNN) classe une observation selon la classe majoritaire parmi ses $k$ plus proches voisins. Ce modèle non paramétrique est adapté car il ne fait aucune hypothèse sur la distribution des données biologiques et peut capturer des frontières de décision non linéaires complexes. Une validation croisée a sélectionné $k=3$ avec un score de 0.929.

\section{Résultats}

\begin{table}[H]
\centering
\caption{Matrice de confusion - KNN ($k=3$)}
\label{tab:confusion_knn}
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Prédit B} & \textbf{Prédit M} \\
\hline
\textbf{Vrai Bénin} & 68 & 4 \\
\hline
\textbf{Vrai Malignant} & 1 & 41 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métriques de performance - KNN}
\label{tab:metrics_knn}
\begin{tabular}{lcc}
\toprule
\textbf{Métrique} & \textbf{B} & \textbf{M} \\
\midrule
Precision & 0.99 & 0.91 \\
Recall & 0.94 & 0.98 \\
F1-score & 0.96 & 0.94 \\
\midrule
Accuracy & \multicolumn{2}{c}{0.96} \\
Macro avg & \multicolumn{2}{c}{0.95} \\
Weighted avg & \multicolumn{2}{c}{0.96} \\
\bottomrule
\end{tabular}
\end{table}

Le modèle KNN avec $k=3$ obtient une précision de 96\%. Il prédit très bien les cas bénins (68 sur 72) mais commet 1 faux négatif sur les cas malins. L'AUC de 0.982 reste élevée mais légèrement inférieure aux autres modèles. Le KNN montre une bonne capacité à identifier les cas bénins et une bonne sensibilité pour les cas malins.

% ==========================================================
\chapter{Random Forest (RF)}

\section{Description du modèle}
Le Random Forest combine plusieurs arbres de décision entraînés sur des échantillons bootstrap avec des sous-ensembles aléatoires de caractéristiques. La prédiction finale résulte d'un vote majoritaire. Ce modèle est adapté car il capture des interactions complexes entre les 30 caractéristiques biologiques, fournit une mesure d'importance des variables, et est robuste au sur-apprentissage. Une validation croisée a optimisé les hyperparamètres : \texttt{max\_depth=5}, \texttt{min\_samples\_split=5}, \texttt{n\_estimators=100}, avec un score de 0.941.

\section{Résultats}

\begin{table}[H]
\centering
\caption{Matrice de confusion - Random Forest}
\label{tab:confusion_rf}
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Prédit B} & \textbf{Prédit M} \\
\hline
\textbf{Vrai Bénin} & 70 & 2 \\
\hline
\textbf{Vrai Malignant} & 1 & 41 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métriques de performance - Random Forest}
\label{tab:metrics_rf}
\begin{tabular}{lcc}
\toprule
\textbf{Métrique} & \textbf{B} & \textbf{M} \\
\midrule
Precision & 0.99 & 0.95 \\
Recall & 0.97 & 0.98 \\
F1-score & 0.98 & 0.96 \\
\midrule
Accuracy & \multicolumn{2}{c}{0.97} \\
Macro avg & \multicolumn{2}{c}{0.97} \\
Weighted avg & \multicolumn{2}{c}{0.97} \\
\bottomrule
\end{tabular}
\end{table}

Le Random Forest obtient d'excellentes performances avec une précision de 97\%. Il prédit très bien les cas bénins (70 sur 72) et commet seulement 1 faux négatif sur les cas malins. L'AUC de 0.997 est la plus élevée parmi tous les modèles testés, égalant celle du LDA. Le modèle présente un excellent équilibre entre précision et rappel pour les deux classes.

% ==========================================================
\chapter{Discussions et Conclusions}

\section{Comparaison des modèles}

\begin{table}[H]
\centering
\caption{Comparaison des performances des modèles}
\label{tab:comparison}
\begin{tabular}{lcccc}
\toprule
\textbf{Modèle} & \textbf{Accuracy} & \textbf{AUC} & \textbf{FP} & \textbf{FN} \\
\midrule
LDA & 0.98 & \textbf{0.997} & \textbf{0} & 2 \\
QDA & 0.94 & 0.989 & 6 & 1 \\
Régression Logistique & \textbf{0.98} & 0.995 & 0 & \textbf{2} \\
KNN ($k=3$) & 0.96 & 0.982 & 4 & 1 \\
Random Forest & \textbf{0.97} & \textbf{0.997} & 2 & 1 \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Analyse des résultats}
Les résultats montrent que tous les modèles obtiennent de très bonnes performances, avec des AUC supérieures à 0.98. La figure~\ref{fig:roc_curves} présente les courbes ROC pour tous les modèles, permettant une comparaison visuelle de leurs capacités discriminantes. Les meilleurs modèles sont le LDA et le Random Forest avec une AUC de 0.997, suivis de près par la régression logistique (0.995).

\begin{figure}[H]
\centering
\includegraphics[width=0.75\textwidth]{Courbes ROC.png}
\caption{Courbes ROC pour tous les modèles de classification. Plus la courbe est proche du coin supérieur gauche, meilleure est la performance du modèle.}
\label{fig:roc_curves}
\end{figure}

Le LDA et la régression logistique présentent les meilleures précisions avec 98\%. Le LDA prédit parfaitement les cas bénins (0 faux positifs) avec seulement 2 faux négatifs. La régression logistique présente également un excellent équilibre avec 0 faux positif et 2 faux négatifs. Le Random Forest obtient également de très bonnes performances avec une précision de 97\%, 2 faux positifs et 1 faux négatif.

Le KNN et le QDA présentent des performances légèrement inférieures, avec respectivement 96\% et 94\% de précision, mais tous les modèles restent très performants avec des AUC supérieures à 0.98.

La PCA avec régression logistique maintient une AUC de 0.996, ce qui montre que la réduction de dimensionnalité préserve bien l'information pertinente pour la classification.

\section{Conclusion}


\end{document}